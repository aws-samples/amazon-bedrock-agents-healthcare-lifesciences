{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VCF Import Status Tracker Setup\n",
    "\n",
    "This notebook sets up the infrastructure for tracking HealthOmics VCF import job statuses with improved Lambda function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install --upgrade -q botocore\n",
    "!python3 -m pip install --upgrade -q boto3\n",
    "!python3 -m pip install --upgrade -q awscli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['AWS_PROFILE'] = 'YOUR_AWS_PROFILE'  # Update with your AWS profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import zipfile\n",
    "import uuid\n",
    "import pprint\n",
    "import logging\n",
    "import botocore.exceptions\n",
    "import subprocess\n",
    "import shutil\n",
    "import sys\n",
    "import re\n",
    "print(f\"Boto3 version: {boto3.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize AWS clients\n",
    "sts_client = boto3.client('sts')\n",
    "iam_client = boto3.client('iam')\n",
    "lambda_client = boto3.client('lambda')\n",
    "dynamodb = boto3.client('dynamodb')\n",
    "omics = boto3.client('omics')\n",
    "s3 = boto3.client('s3')\n",
    "events_client = boto3.client('events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get AWS account information\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"Account ID: {account_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create DynamoDB Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DynamoDB table for tracking VCF import jobs\n",
    "table_name = 'VcfImportTracking3'\n",
    "\n",
    "try:\n",
    "    response = dynamodb.create_table(\n",
    "        TableName=table_name,\n",
    "        AttributeDefinitions=[\n",
    "            {\n",
    "                'AttributeName': 'SampleID',\n",
    "                'AttributeType': 'S'\n",
    "            }\n",
    "        ],\n",
    "        KeySchema=[\n",
    "            {\n",
    "                'AttributeName': 'SampleID',\n",
    "                'KeyType': 'HASH'\n",
    "            }\n",
    "        ],\n",
    "        BillingMode='PAY_PER_REQUEST'\n",
    "    )\n",
    "    print(f\"✅ Table {table_name} created successfully!\")\n",
    "    print(f\"Status: {response['TableDescription']['TableStatus']}\")\n",
    "    \n",
    "except botocore.exceptions.ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'ResourceInUseException':\n",
    "        print(f\"✅ Table {table_name} already exists\")\n",
    "    else:\n",
    "        print(f\"❌ Error creating table: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create IAM Role for Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create IAM role for Lambda function\n",
    "role_name = 'VcfProcessorLambdaRole3'\n",
    "\n",
    "# Trust policy for Lambda\n",
    "lambda_trust_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": [\n",
    "                    \"lambda.amazonaws.com\",\n",
    "                    \"omics.amazonaws.com\"\n",
    "                ]\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Check if role exists\n",
    "    try:\n",
    "        iam_client.get_role(RoleName=role_name)\n",
    "        print(f\"✅ Role {role_name} already exists\")\n",
    "    except iam_client.exceptions.NoSuchEntityException:\n",
    "        # Create the role\n",
    "        iam_client.create_role(\n",
    "            RoleName=role_name,\n",
    "            AssumeRolePolicyDocument=json.dumps(lambda_trust_policy),\n",
    "            Description='Role for VCF Processor Lambda function'\n",
    "        )\n",
    "        print(f\"✅ Role {role_name} created successfully!\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error with role operation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach comprehensive policy to the role\n",
    "policy_name = 'VcfProcessorPolicy3'\n",
    "\n",
    "lambda_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"logs:CreateLogGroup\",\n",
    "                \"logs:CreateLogStream\",\n",
    "                \"logs:PutLogEvents\"\n",
    "            ],\n",
    "            \"Resource\": \"arn:aws:logs:*:*:*\"\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:GetBucketLocation\",\n",
    "                \"s3:PutObject\",\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:ListBucket\",\n",
    "                \"s3:AbortMultipartUpload\",\n",
    "                \"s3:ListMultipartUploadParts\",\n",
    "                \"s3:GetObjectAcl\",\n",
    "                \"s3:PutObjectAcl\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"dynamodb:PutItem\",\n",
    "                \"dynamodb:UpdateItem\",\n",
    "                \"dynamodb:GetItem\",\n",
    "                \"dynamodb:Scan\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                f\"arn:aws:dynamodb:*:*:table/{table_name}\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"omics:StartVariantImportJob\",\n",
    "                \"omics:GetVariantImportJob\",\n",
    "                \"omics:ListVariantStores\",\n",
    "                \"omics:CreateVariantStore\",\n",
    "                \"omics:GetVariantStore\",\n",
    "                \"omics:ListReferenceStores\",\n",
    "                \"omics:GetReferenceStore\",\n",
    "                \"omics:ListReferences\", \n",
    "                \"omics:GetReference\",\n",
    "                \"omics:GetReferenceMetadata\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"ram:AcceptResourceShareInvitation\",\n",
    "                \"ram:GetResourceShareInvitations\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"lakeformation:GrantPermissions\",\n",
    "                \"lakeformation:RevokePermissions\",\n",
    "                \"lakeformation:ListPermissions\",\n",
    "                \"lakeformation:GetDataAccess\",\n",
    "                \"lakeformation:GetDataLakeSettings\",\n",
    "                \"lakeformation:PutDataLakeSettings\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"glue:CreateTable\",\n",
    "                \"glue:GetTable\",\n",
    "                \"glue:UpdateTable\",\n",
    "                \"glue:DeleteTable\",\n",
    "                \"glue:GetTables\",\n",
    "                \"glue:GetDatabase\",\n",
    "                \"glue:GetDatabases\",\n",
    "                \"lakeformation:GetDataAccess\",\n",
    "                \"lakeformation:GrantPermissions\",\n",
    "                \"lakeformation:RevokePermissions\",\n",
    "                \"lakeformation:ListPermissions\",\n",
    "                \"lakeformation:GetResourceLFTags\",\n",
    "                \"lakeformation:ListLFTags\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": \"iam:PassRole\",\n",
    "            \"Resource\": f\"arn:aws:iam::{account_id}:role/{role_name}\"\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"kms:Decrypt\",\n",
    "                \"kms:DescribeKey\",\n",
    "                \"kms:GenerateDataKey\",\n",
    "                \"kms:Encrypt\"\n",
    "            ],\n",
    "             \"Resource\": \"arn:aws:kms:us-east-1:AWS_ACCOUNT_ID:key/AWS_KMS_KEY_ID\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Check if policy exists\n",
    "    try:\n",
    "        iam_client.get_role_policy(RoleName=role_name, PolicyName=policy_name)\n",
    "        print(f\"✅ Policy {policy_name} already exists on role\")\n",
    "    except iam_client.exceptions.NoSuchEntityException:\n",
    "        # Attach the policy\n",
    "        iam_client.put_role_policy(\n",
    "            RoleName=role_name,\n",
    "            PolicyName=policy_name,\n",
    "            PolicyDocument=json.dumps(lambda_policy)\n",
    "        )\n",
    "        print(f\"✅ Policy {policy_name} attached to role successfully!\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error with policy operation: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setup HealthOmics Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create reference store"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Get the role_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_role_arn(role_name):\n",
    "    try:\n",
    "        iam = boto3.resource('iam')\n",
    "        role = iam.Role(role_name)\n",
    "        role.load()  # calls GetRole to load attributes\n",
    "    except ClientError:\n",
    "        print(\"Couldn't get role named %s.\"%role_name)\n",
    "        raise\n",
    "    else:\n",
    "        return role.arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omics = boto3.client('omics', region_name='us-east-1')\n",
    "list_ref_stores = omics.list_reference_stores()\n",
    "ref_store = list_ref_stores.get('referenceStores')\n",
    "if not ref_store:\n",
    "    response = omics.create_reference_store(name='RefStore')\n",
    "    print(response)\n",
    "    ref_store_id = response['id']\n",
    "else:\n",
    "    ref_store_id = ref_store[0]['id']\n",
    "ref_store_id\n",
    "# reference_s3_uri = 's3://YOUR_S3_BUCKET/YOUR_PREFIX/hg38_alt_aware_nohla.fa'\n",
    "# ref_import_job = omics.start_reference_import_job(\n",
    "#     referenceStoreId = ref_store_id,\n",
    "#     roleArn = get_role_arn(role_name),\n",
    "#     sources=[{\n",
    "#         'sourceFile': reference_s3_uri,\n",
    "#         'name': 'YOUR_REFERENCE_NAME',\n",
    "#         'tags': {'SourceLocation': '1kg'}\n",
    "#    }])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ref_import_job = omics.get_reference_import_job(\n",
    "    referenceStoreId=ref_store_id, \n",
    "    id=ref_import_job['id'])\n",
    "ref_import_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = omics.list_references(referenceStoreId=ref_store_id,\n",
    "    filter ={\"name\": \"YOUR_REFERENCE_NAME\"})\n",
    "print(ref)\n",
    "reference_id = ref['references'][0]['id']\n",
    "reference_arn = ref['references'][0]['arn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Variant store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_store_name = f'YOUR_VARIANT_STORE_NAME'\n",
    "ref_name = 'YOUR_REFERENCE_NAME'  ## Change this reference name to match one you have created if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Initialize the omics client\n",
    "omics = boto3.client('omics')\n",
    "\n",
    "def get_existing_variant_store(store_name):\n",
    "    \"\"\"Check if a variant store with the given name already exists\"\"\"\n",
    "    try:\n",
    "        # List all variant stores\n",
    "        response = omics.list_variant_stores()\n",
    "        # Check if any store matches the name\n",
    "        for store in response.get('variantStores', []):\n",
    "            if store['name'] == store_name:\n",
    "                return store\n",
    "        return None\n",
    "    except ClientError as e:\n",
    "        print(f\"Error listing variant stores: {e}\")\n",
    "        return None\n",
    "\n",
    "try:\n",
    "    # Try to create the variant store\n",
    "    response = omics.create_variant_store(\n",
    "        name=var_store_name, \n",
    "        reference={\"referenceArn\": reference_arn}\n",
    "    )\n",
    "    var_store = response\n",
    "    print(f\"Created new variant store: {response['id']}\")\n",
    "    \n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'ConflictException':\n",
    "        # Store already exists, get the existing one\n",
    "        print(f\"Variant store '{var_store_name}' already exists, retrieving existing store...\")\n",
    "        existing_store = get_existing_variant_store(var_store_name)\n",
    "        if existing_store:\n",
    "            var_store = existing_store\n",
    "            response = existing_store\n",
    "        else:\n",
    "            raise Exception(f\"Could not find existing variant store: {var_store_name}\")\n",
    "    else:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_store = omics.get_variant_store(name=var_store['name'])\n",
    "print (var_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - Update these values for your setup\n",
    "var_store_name = 'YOUR_VARIANT_STORE_NAME'  # Update with your variant store name\n",
    "reference_arn = 'arn:aws:omics:us-east-1:AWS_ACCOUNT_ID:referenceStore/YOUR_REF_STORE_ID/reference/YOUR_REFERENCE_ID'  # Update with your reference ARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enable_analytics_via_cli():\n",
    "    \"\"\"Enable HealthOmics Analytics using AWS CLI\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # AWS CLI command to enable analytics\n",
    "        cmd = [\n",
    "            'aws', 'omics', 'update-variant-store',\n",
    "            '--name', 'YOUR_VARIANT_STORE_NAME',\n",
    "            '--description', 'Store with analytics enabled for Athena queries',\n",
    "            '--region', 'us-east-1'\n",
    "        ]\n",
    "        \n",
    "        print(\"🔧 Running AWS CLI command...\")\n",
    "        print(f\"Command: {' '.join(cmd)}\")\n",
    "        \n",
    "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"✅ Command executed successfully!\")\n",
    "            print(\"Response:\", result.stdout)\n",
    "            return True\n",
    "        else:\n",
    "            print(\"❌ Command failed!\")\n",
    "            print(\"Error:\", result.stderr)\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error executing command: {e}\")\n",
    "        return False\n",
    "\n",
    "# Run the command\n",
    "success = enable_analytics_via_cli()\n",
    "\n",
    "if success:\n",
    "    print(\"\\n🎯 Next steps:\")\n",
    "    print(\"1. Wait 10-15 minutes for analytics to be fully enabled\")\n",
    "    print(\"2. Try your Athena queries again\")\n",
    "    print(\"3. The resource links should now work properly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get variant store details\n",
    "if var_store:\n",
    "    try:\n",
    "        var_store_details = omics.get_variant_store(name=var_store['name'])\n",
    "        print(f\"📋 Variant Store Details:\")\n",
    "        print(f\"   Name: {var_store_details['name']}\")\n",
    "        print(f\"   ID: {var_store_details['id']}\")\n",
    "        print(f\"   Status: {var_store_details['status']}\")\n",
    "        print(f\"   ARN: {var_store_details['storeArn']}\")\n",
    "        \n",
    "        # Store these for Lambda environment variables\n",
    "        variant_store_name = var_store_details['name']\n",
    "        variant_store_id = var_store_details['id']\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error getting variant store details: {e}\")\n",
    "else:\n",
    "    print(\"❌ No variant store available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Deploy Improved Lambda Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda deployment functions\n",
    "def create_lambda_zip(source_file, output_zip):\n",
    "    \"\"\"Create a zip file containing the Lambda function code and dependencies\"\"\"\n",
    "    print(f\"Creating zip file {output_zip} with {source_file} and dependencies\")\n",
    "    \n",
    "    temp_dir = \"lambda_package_temp\"\n",
    "    if os.path.exists(temp_dir):\n",
    "        shutil.rmtree(temp_dir)\n",
    "    os.makedirs(temp_dir)\n",
    "    \n",
    "    try:\n",
    "        # Copy the source file\n",
    "        source_filename = os.path.basename(source_file)\n",
    "        shutil.copy(source_file, os.path.join(temp_dir, source_filename))\n",
    "        \n",
    "        # Install dependencies\n",
    "        print(\"Installing dependencies...\")\n",
    "        subprocess.check_call([\n",
    "            sys.executable, \"-m\", \"pip\", \"install\", \n",
    "            \"boto3\", \"botocore\", \n",
    "            \"--target\", temp_dir, \n",
    "            \"--no-cache-dir\"\n",
    "        ])\n",
    "        \n",
    "        # Create the zip file\n",
    "        with zipfile.ZipFile(output_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            for root, _, files in os.walk(temp_dir):\n",
    "                for file in files:\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    arcname = os.path.relpath(file_path, temp_dir)\n",
    "                    zipf.write(file_path, arcname)\n",
    "        \n",
    "        print(f\"✅ Successfully created {output_zip} with dependencies\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error creating zip file: {e}\")\n",
    "        return False\n",
    "    finally:\n",
    "        if os.path.exists(temp_dir):\n",
    "            shutil.rmtree(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_lambda_function(function_name, zip_file, role_arn, handler, runtime, timeout, environment_vars):\n",
    "    \"\"\"Deploy or update Lambda function\"\"\"\n",
    "    \n",
    "    try:\n",
    "        with open(zip_file, 'rb') as file_data:\n",
    "            zip_bytes = file_data.read()\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error reading zip file: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Check if function exists\n",
    "    try:\n",
    "        lambda_client.get_function(FunctionName=function_name)\n",
    "        function_exists = True\n",
    "        print(f\"🔄 Lambda function {function_name} exists. Updating...\")\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == 'ResourceNotFoundException':\n",
    "            function_exists = False\n",
    "            print(f\"🆕 Creating new Lambda function {function_name}...\")\n",
    "        else:\n",
    "            print(f\"❌ Error checking Lambda function: {e}\")\n",
    "            return None\n",
    "    \n",
    "    try:\n",
    "        if function_exists:\n",
    "            # Update function code\n",
    "            print(\"Updating function code...\")\n",
    "            lambda_client.update_function_code(\n",
    "                FunctionName=function_name,\n",
    "                ZipFile=zip_bytes\n",
    "            )\n",
    "            \n",
    "            # Wait for update to complete\n",
    "            print(\"Waiting for code update to complete...\")\n",
    "            time.sleep(10)  # Simple wait\n",
    "            \n",
    "            # Update configuration\n",
    "            print(\"Updating function configuration...\")\n",
    "            response = lambda_client.update_function_configuration(\n",
    "                FunctionName=function_name,\n",
    "                Role=role_arn,\n",
    "                Handler=handler,\n",
    "                Runtime=runtime,\n",
    "                Timeout=timeout,\n",
    "                Environment={\n",
    "                    'Variables': environment_vars\n",
    "                }\n",
    "            )\n",
    "            print(f\"✅ Lambda function {function_name} updated successfully!\")\n",
    "            return response\n",
    "        else:\n",
    "            # Create new function\n",
    "            response = lambda_client.create_function(\n",
    "                FunctionName=function_name,\n",
    "                Runtime=runtime,\n",
    "                Role=role_arn,\n",
    "                Handler=handler,\n",
    "                Code={\n",
    "                    'ZipFile': zip_bytes\n",
    "                },\n",
    "                Timeout=timeout,\n",
    "                Environment={\n",
    "                    'Variables': environment_vars\n",
    "                }\n",
    "            )\n",
    "            print(f\"✅ Lambda function {function_name} created successfully!\")\n",
    "            return response\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error deploying Lambda function: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the improved Lambda function\n",
    "# Make sure you have lambda_function_fixed_final.py in the current directory\n",
    "\n",
    "# Parameters\n",
    "source_file = 'lambda_function_fixed_final.py'  # Use the fixed_final version\n",
    "zip_file = 'lambda_function.zip'\n",
    "function_name = 'VcfProcessor3'\n",
    "runtime = 'python3.9'\n",
    "handler = 'lambda_function_fixed_final.lambda_handler'  # Updated handler\n",
    "role_arn = f'arn:aws:iam::{account_id}:role/{role_name}'\n",
    "timeout = 900\n",
    "\n",
    "# Environment variables for Lambda\n",
    "environment_vars = {\n",
    "    'VARIANT_STORE_NAME': variant_store_name,\n",
    "    'VARIANT_STORE_ID': variant_store_id,\n",
    "    'DYNAMODB_TABLE': table_name\n",
    "}\n",
    "\n",
    "print(f\"📦 Deploying Lambda function with:\")\n",
    "print(f\"   Source: {source_file}\")\n",
    "print(f\"   Function Name: {function_name}\")\n",
    "print(f\"   Variant Store: {variant_store_name} ({variant_store_id})\")\n",
    "print(f\"   DynamoDB Table: {table_name}\")\n",
    "\n",
    "# Execute deployment\n",
    "if create_lambda_zip(source_file, zip_file):\n",
    "    response = deploy_lambda_function(\n",
    "        function_name,\n",
    "        zip_file,\n",
    "        role_arn,\n",
    "        handler,\n",
    "        runtime,\n",
    "        timeout,\n",
    "        environment_vars\n",
    "    )\n",
    "    \n",
    "    if response:\n",
    "        print(f\"🎯 Function ARN: {response.get('FunctionArn')}\")\n",
    "        print(f\"📊 Function State: {response.get('State')}\")\n",
    "        lambda_function_arn = response.get('FunctionArn')\n",
    "    else:\n",
    "        print(\"❌ Failed to deploy Lambda function\")\n",
    "else:\n",
    "    print(\"❌ Failed to create deployment package\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Configure S3 Event Trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure S3 bucket to trigger Lambda on VCF file uploads\n",
    "def configure_s3_event_notification(s3_uri, lambda_function_arn, event_types, suffix=None):\n",
    "    \"\"\"Configure S3 bucket to trigger Lambda function on specified events\"\"\"\n",
    "    \n",
    "    # Parse S3 URI\n",
    "    match = re.match(r's3://([^/]+)/?(.*)', s3_uri)\n",
    "    if not match:\n",
    "        raise ValueError(f\"Invalid S3 URI format: {s3_uri}\")\n",
    "    \n",
    "    bucket_name = match.group(1)\n",
    "    prefix = match.group(2)\n",
    "    \n",
    "    # Create filter rules\n",
    "    filter_rules = []\n",
    "    if prefix:\n",
    "        filter_rules.append({'Name': 'prefix', 'Value': prefix})\n",
    "    if suffix:\n",
    "        filter_rules.append({'Name': 'suffix', 'Value': suffix})\n",
    "    \n",
    "    # Create notification configuration\n",
    "    notification_config = {\n",
    "        'LambdaFunctionConfigurations': [\n",
    "            {\n",
    "                'LambdaFunctionArn': lambda_function_arn,\n",
    "                'Events': event_types\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    if filter_rules:\n",
    "        notification_config['LambdaFunctionConfigurations'][0]['Filter'] = {\n",
    "            'Key': {'FilterRules': filter_rules}\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        # Add Lambda permission for S3\n",
    "        statement_id = f\"s3-{bucket_name}-to-lambda-{lambda_function_arn.split(':')[-1]}\"\n",
    "        \n",
    "        try:\n",
    "            lambda_client.add_permission(\n",
    "                FunctionName=lambda_function_arn,\n",
    "                StatementId=statement_id,\n",
    "                Action='lambda:InvokeFunction',\n",
    "                Principal='s3.amazonaws.com',\n",
    "                SourceArn=f\"arn:aws:s3:::{bucket_name}\"\n",
    "            )\n",
    "            print(f\"✅ Added S3 permission for bucket {bucket_name}\")\n",
    "        except botocore.exceptions.ClientError as e:\n",
    "            if e.response['Error']['Code'] == 'ResourceConflictException':\n",
    "                print(f\"✅ S3 permission already exists for bucket {bucket_name}\")\n",
    "            else:\n",
    "                print(f\"❌ Error adding S3 permission: {e}\")\n",
    "                return False\n",
    "        \n",
    "        # Apply notification configuration\n",
    "        s3.put_bucket_notification_configuration(\n",
    "            Bucket=bucket_name,\n",
    "            NotificationConfiguration=notification_config\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ S3 event notification configured for bucket {bucket_name} with prefix '{prefix}'\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error configuring S3 event notification: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure S3 event trigger\n",
    "# Update this S3 URI to match your bucket and prefix\n",
    "s3_uri = \"s3://YOUR_S3_BUCKET/YOUR_PREFIX/\"  # UPDATE THIS\n",
    "event_types = ['s3:ObjectCreated:*']\n",
    "suffix = '.hard-filtered.vcf.gz'\n",
    "\n",
    "print(f\"🔗 Configuring S3 event trigger:\")\n",
    "print(f\"   S3 URI: {s3_uri}\")\n",
    "print(f\"   File suffix: {suffix}\")\n",
    "print(f\"   Lambda ARN: {lambda_function_arn}\")\n",
    "\n",
    "if 'lambda_function_arn' in locals():\n",
    "    success = configure_s3_event_notification(\n",
    "        s3_uri,\n",
    "        lambda_function_arn,\n",
    "        event_types,\n",
    "        suffix\n",
    "    )\n",
    "    \n",
    "    if success:\n",
    "        print(\"🎉 S3 event notification configured successfully!\")\n",
    "    else:\n",
    "        print(\"❌ Failed to configure S3 event notification\")\n",
    "else:\n",
    "    print(\"⚠️ Lambda function ARN not available. Deploy Lambda function first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Setup Scheduled Status Checking (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optional: Set up EventBridge rule for scheduled status checking\n",
    "# # This provides a fallback mechanism for status updates\n",
    "\n",
    "# RULE_NAME = \"VcfStatusCheckSchedule\"\n",
    "# SCHEDULE_EXPRESSION = \"rate(10 minutes)\"  # Check every 10 minutes\n",
    "\n",
    "# print(f\"⏰ Setting up scheduled status checking:\")\n",
    "# print(f\"   Rule Name: {RULE_NAME}\")\n",
    "# print(f\"   Schedule: {SCHEDULE_EXPRESSION}\")\n",
    "\n",
    "# try:\n",
    "#     # Create EventBridge rule\n",
    "#     rule_response = events_client.put_rule(\n",
    "#         Name=RULE_NAME,\n",
    "#         ScheduleExpression=SCHEDULE_EXPRESSION,\n",
    "#         Description=\"Triggers VCF status checker as fallback\",\n",
    "#         State='ENABLED'\n",
    "#     )\n",
    "#     print(f\"✅ EventBridge rule created: {rule_response['RuleArn']}\")\n",
    "    \n",
    "#     # Add Lambda as target\n",
    "#     if 'lambda_function_arn' in locals():\n",
    "#         target_response = events_client.put_targets(\n",
    "#             Rule=RULE_NAME,\n",
    "#             Targets=[\n",
    "#                 {\n",
    "#                     'Id': '1',\n",
    "#                     'Arn': lambda_function_arn\n",
    "#                 }\n",
    "#             ]\n",
    "#         )\n",
    "        \n",
    "#         if target_response['FailedEntryCount'] == 0:\n",
    "#             print(f\"✅ Lambda function added as EventBridge target\")\n",
    "#         else:\n",
    "#             print(f\"❌ Failed to add Lambda as target: {target_response['FailedEntries']}\")\n",
    "        \n",
    "#         # Grant EventBridge permission to invoke Lambda\n",
    "#         try:\n",
    "#             lambda_client.add_permission(\n",
    "#                 FunctionName=function_name,\n",
    "#                 StatementId=\"AllowExecutionFromEventBridge\",\n",
    "#                 Action=\"lambda:InvokeFunction\",\n",
    "#                 Principal=\"events.amazonaws.com\",\n",
    "#                 SourceArn=f\"arn:aws:events:{region}:{account_id}:rule/{RULE_NAME}\"\n",
    "#             )\n",
    "#             print(f\"✅ EventBridge permission granted\")\n",
    "#         except botocore.exceptions.ClientError as e:\n",
    "#             if e.response['Error']['Code'] == 'ResourceConflictException':\n",
    "#                 print(f\"✅ EventBridge permission already exists\")\n",
    "#             else:\n",
    "#                 print(f\"❌ Error granting EventBridge permission: {e}\")\n",
    "#     else:\n",
    "#         print(\"⚠️ Lambda function ARN not available for EventBridge target\")\n",
    "        \n",
    "# except Exception as e:\n",
    "#     print(f\"❌ Error setting up EventBridge rule: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Testing and Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check DynamoDB table contents\n",
    "def show_all_records():\n",
    "    dynamodb = boto3.resource('dynamodb')\n",
    "    table = dynamodb.Table(table_name)\n",
    "    \n",
    "    items = table.scan()['Items']\n",
    "    print(f\"Found {len(items)} records:\\n\")\n",
    "    \n",
    "    for i, item in enumerate(items, 1):\n",
    "        print(f\"Record {i}:\")\n",
    "        for key, value in item.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "        print()\n",
    "\n",
    "show_all_records()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing variant store queries"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "** Query in Athena **\n",
    "\n",
    "To query data in athena, we need to create resource links to the tables using the AWS Lakeformation console. The user will also need to be a datalake administrator to do this.\n",
    "\n",
    "The following code will create resource links to the default database in the AwsDataCatalog in AWS Glue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "ram = boto3.client('ram')\n",
    "glue = boto3.client('glue')\n",
    "\n",
    "caller_identity = boto3.client('sts').get_caller_identity()\n",
    "AWS_ACCOUNT_ID = caller_identity['Account']\n",
    "AWS_IDENITY_ARN = caller_identity['Arn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll list available shared resources from OTHER-ACCOUNTS in AWS RAM and look for the resource that matches the id of the Variant store we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ram.list_resources(resourceOwner='OTHER-ACCOUNTS', resourceType='glue:Database')\n",
    "\n",
    "if not response.get('resources'):\n",
    "    print('no shared resources found. verify that you have successfully created an Omics Analytics store')\n",
    "else:\n",
    "    variantstore_resources = [resource for resource in response['resources'] if var_store['id'] in resource['arn']]\n",
    "    if not variantstore_resources:\n",
    "        print(f\"no shared resources matching variant store id {var_store['id']} found\")\n",
    "    else:\n",
    "        variantstore_resource = variantstore_resources[0]\n",
    "\n",
    "variantstore_resource"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Next, we'll get the specific resource share the Variant store is associated with. This is so we can get the owningAccountId attribute for the share. (Note we could also do this by parsing the resourceShareArn for the resource above, but doing it this way is more explicit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_share = ram.get_resource_shares(\n",
    "    resourceOwner='OTHER-ACCOUNTS', \n",
    "    resourceShareArns=[variantstore_resource['resourceShareArn']])['resourceShares'][0]\n",
    "resource_share"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_your_own_database():\n",
    "    \"\"\"Create your own database instead of using the shared one\"\"\"\n",
    "    \n",
    "    glue = boto3.client('glue')\n",
    "    lakeformation = boto3.client('lakeformation')\n",
    "    sts_client = boto3.client('sts')\n",
    "    \n",
    "    account_id = sts_client.get_caller_identity()['Account']\n",
    "    role_arn = f'arn:aws:iam::{account_id}:role/VcfProcessorLambdaRole3'\n",
    "    \n",
    "    # Create your own database\n",
    "    database_name = 'vcf_analysis_db'\n",
    "    \n",
    "    try:\n",
    "        # Create database\n",
    "        glue.create_database(\n",
    "            DatabaseInput={\n",
    "                'Name': database_name,\n",
    "                'Description': 'Database for VCF analysis and genomics data'\n",
    "            }\n",
    "        )\n",
    "        print(f\"✅ Created database: {database_name}\")\n",
    "        \n",
    "        # Grant yourself ALL permissions on your own database\n",
    "        lakeformation.grant_permissions(\n",
    "            Principal={\n",
    "                'DataLakePrincipalIdentifier': role_arn\n",
    "            },\n",
    "            Resource={\n",
    "                'Database': {\n",
    "                    'Name': database_name\n",
    "                }\n",
    "            },\n",
    "            Permissions=['ALL']\n",
    "        )\n",
    "        print(f\"✅ Granted ALL permissions on {database_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "\n",
    "# Run this instead\n",
    "create_your_own_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have resource links created, we can start quering the data using Amazon Athena. You don't need to wait for all the import jobs to complete to start doing this. Queries can be made while data imports in the background.\n",
    "\n",
    "To query Amazon Omics Analytics stores, you need to use Athena engine version 3. The following code checks if you have an existing Athena workgroup that satisfies this criteria. If not it will create one called omics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Delete a single table\n",
    "# try:\n",
    "#     response = glue.delete_table(\n",
    "#         DatabaseName='vcf_analysis_db',\n",
    "#         Name=var_store['name']\n",
    "#     )\n",
    "#     print(f\"Table deleted successfully: {response}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error deleting table: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "glue.create_table(\n",
    "    DatabaseName='vcf_analysis_db',\n",
    "    TableInput = {\n",
    "        \"Name\": var_store['name'],\n",
    "        \"TargetTable\": {\n",
    "            \"CatalogId\": resource_share['owningAccountId'],\n",
    "            \"DatabaseName\": f\"variant_{account_id}_{var_store['id']}\",\n",
    "            \"Name\": var_store['name'],\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "athena = boto3.client('athena')\n",
    "athena_workgroups = athena.list_work_groups()['WorkGroups']\n",
    "athena_workgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "athena_workgroup = None\n",
    "for wg in athena_workgroups:\n",
    "    print(wg['EngineVersion']['EffectiveEngineVersion'])\n",
    "    if wg['EngineVersion']['EffectiveEngineVersion'] == 'Athena engine version 3':\n",
    "        print(f\"Workgroup '{wg['Name']}' found using Athena engine version 3\")\n",
    "        athena_workgroup = wg\n",
    "        break\n",
    "else:\n",
    "    print(\"No workgroups with Athena engine version 3 found. creating one\")\n",
    "    athena_workgroup = athena.create_work_group(\n",
    "        Name='omics',\n",
    "        Configuration={\n",
    "            \"EngineVersion\": {\n",
    "                \"SelectedEngineVersion\": \"Athena engine version 3\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "athena_workgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install awswrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awswrangler as wr\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enable_analytics_via_cli():\n",
    "    \"\"\"Enable HealthOmics Analytics using AWS CLI\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # AWS CLI command to enable analytics\n",
    "        cmd = [\n",
    "            'aws', 'omics', 'update-variant-store',\n",
    "            '--name', 'hcagentsvs3',\n",
    "            '--description', 'Store with analytics enabled for Athena queries',\n",
    "            '--region', 'us-east-1'\n",
    "        ]\n",
    "        \n",
    "        print(\"🔧 Running AWS CLI command...\")\n",
    "        print(f\"Command: {' '.join(cmd)}\")\n",
    "        \n",
    "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"✅ Command executed successfully!\")\n",
    "            print(\"Response:\", result.stdout)\n",
    "            return True\n",
    "        else:\n",
    "            print(\"❌ Command failed!\")\n",
    "            print(\"Error:\", result.stderr)\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error executing command: {e}\")\n",
    "        return False\n",
    "\n",
    "# Run the command\n",
    "success = enable_analytics_via_cli()\n",
    "\n",
    "if success:\n",
    "    print(\"\\n🎯 Next steps:\")\n",
    "    print(\"1. Wait 10-15 minutes for analytics to be fully enabled\")\n",
    "    print(\"2. Try your Athena queries again\")\n",
    "    print(\"3. The resource links should now work properly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_query = \"SELECT * from vcf_analysis_db.hcagentsvs3 LIMIT 10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awswrangler as wr\n",
    "\n",
    "# This should work now (after analytics enables):\n",
    "df = wr.athena.read_sql_query(\n",
    "    \"SELECT * FROM vcf_analysis_db.YOUR_VARIANT_STORE_NAME LIMIT 5\",\n",
    "    database=\"vcf_analysis_db\",\n",
    "    workgroup=\"datasets-workgroup\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glue.create_table(\n",
    "    DatabaseName='vcf_analysis_db',\n",
    "    TableInput = {\n",
    "        \"Name\": \"annotationstore_cliinvar\",\n",
    "        \"TargetTable\": {\n",
    "            \"CatalogId\": resource_share['owningAccountId'],\n",
    "            \"DatabaseName\": f\"variant_{account_id}_YOUR_ANNOTATION_STORE_ID\",\n",
    "            \"Name\": \"annotationstore_cliinvar\",\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_query = \"SELECT * from vcf_analysis_db.YOUR_VARIANT_STORE_NAME LIMIT 10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awswrangler as wr\n",
    "\n",
    "# This should work now (after analytics enables):\n",
    "df = wr.athena.read_sql_query(\n",
    "    \"SELECT * FROM vcf_analysis_db.YOUR_VARIANT_STORE_NAME LIMIT 5\",\n",
    "    database=\"vcf_analysis_db\",\n",
    "    workgroup=\"datasets-workgroup\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 8. Setup Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display setup summary\n",
    "print(\"🎉 VCF Import Status Tracker Setup Complete!\")\n",
    "print(\"=\" * 50)\n",
    "print()\n",
    "print(\"📋 Components Created:\")\n",
    "print(f\"   ✅ DynamoDB Table: {table_name}\")\n",
    "print(f\"   ✅ IAM Role: {role_name}\")\n",
    "print(f\"   ✅ Lambda Function: {function_name}\")\n",
    "if 'variant_store_name' in locals():\n",
    "    print(f\"   ✅ Variant Store: {variant_store_name} ({variant_store_id})\")\n",
    "print(f\"   ✅ S3 Event Trigger: Configured\")\n",
    "print(f\"   ✅ Scheduled Status Check: {RULE_NAME}\")\n",
    "print()\n",
    "print(\"🔧 Key Improvements in Lambda Function:\")\n",
    "print(\"   ✅ fixed_final status checking logic\")\n",
    "print(\"   ✅ Always updates DynamoDB to match HealthOmics status\")\n",
    "print(\"   ✅ Better error handling for missing jobs\")\n",
    "print(\"   ✅ Consistent timestamp formatting\")\n",
    "print(\"   ✅ Clearer logging and debugging\")\n",
    "print()\n",
    "print(\"📊 Monitoring:\")\n",
    "print(f\"   📈 CloudWatch Logs: /aws/lambda/{function_name}\")\n",
    "print(f\"   📊 DynamoDB Table: {table_name}\")\n",
    "print(f\"   ⚡ HealthOmics EventBridge Rule: {OMICS_RULE_NAME}\")\n",
    "print()\n",
    "print(\"🚀 Next Steps:\")\n",
    "print(\"   1. Update S3 URI in the S3 event configuration section\")\n",
    "print(\"   2. Upload a test VCF file to trigger the workflow\")\n",
    "print(\"   3. Monitor CloudWatch logs for execution details\")\n",
    "print(\"   4. Check DynamoDB table for real-time status updates\")\n",
    "print(\"   5. Verify that status updates happen instantly when jobs complete\")\n",
    "print()\n",
    "print(\"🔍 Troubleshooting:\")\n",
    "print(\"   - Check CloudWatch logs if jobs fail\")\n",
    "print(\"   - Verify IAM permissions if access denied\")\n",
    "print(\"   - Ensure S3 bucket and prefix are correct\")\n",
    "print(\"   - Confirm HealthOmics variant store is active\")\n",
    "print(\"   - Use manual status check for debugging if needed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
