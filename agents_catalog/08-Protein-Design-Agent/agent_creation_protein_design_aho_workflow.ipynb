{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Protein Design Agent with AWS HealthOmics Workflow Integration\n",
    "\n",
    "This notebook demonstrates how to create a Bedrock agent that can trigger AWS HealthOmics workflows for protein design optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-requisites\n",
    "\n",
    "1. Go through the notebook environment setup in the agents_catalog/0-Notebook-environment/ folder\n",
    "\n",
    "2. Deploy cf_template.yaml to your AWS account to instantiate a ECR repository with a custom Docker image, a AWS HealthOmics (AHO) private workflow, and a lambda function that invokes the AHO workflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps for deploying the CloudFormation stack:\n",
    "1. Upload workflow definition files to S3\n",
    "2. Package and upload container code to S3\n",
    "3. Deploy the CloudFormation stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import boto3\n",
    "\n",
    "\n",
    "# Create zip file of container code\n",
    "def create_container_zip():\n",
    "    try:\n",
    "        shutil.make_archive('code', 'zip', 'container')\n",
    "        print(\"Successfully created code.zip from container directory\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating zip file: {e}\")\n",
    "\n",
    "# Upload workflow files and container code to S3\n",
    "def upload_to_s3(bucket_name):\n",
    "    s3 = boto3.client('s3')\n",
    "    \n",
    "    # Upload workflow files\n",
    "    workflow_files = ['main.nf', 'nextflow.config', 'config.yaml', 'parameter-template.json']\n",
    "    for file in workflow_files:\n",
    "        try:\n",
    "            s3.upload_file(\n",
    "                f'aho_workflow/{file}', \n",
    "                bucket_name, \n",
    "                f'workflow/{file}'\n",
    "            )\n",
    "            print(f\"Uploaded {file} to s3://{bucket_name}/workflow/\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error uploading {file}: {e}\")\n",
    "    \n",
    "    # Upload container code zip\n",
    "    try:\n",
    "        s3.upload_file(\n",
    "            'code.zip',\n",
    "            bucket_name,\n",
    "            'code.zip'\n",
    "        )\n",
    "        print(f\"Uploaded code.zip to s3://{bucket_name}/\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading code.zip: {e}\")\n",
    "\n",
    "# Create zip and upload files\n",
    "s3_bucket_name = \"hcls-bedrock-agents-byot-aho\"\n",
    "create_container_zip()\n",
    "upload_to_s3(s3_bucket_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS CLI commands to deploy the CloudFormation stack:\n",
    "````\n",
    "# Deploy the CloudFormation stack\n",
    "aws cloudformation create-stack \\\\\n",
    "    --stack-name hcls-bedrock-agents-byot-aho-stack \\\\\n",
    "    --template-body file://cf_template.yaml \\\\\n",
    "    --parameters file://cf_parameters.json \\\\\n",
    "    --capabilities CAPABILITY_IAM CAPABILITY_AUTO_EXPAND CAPABILITY_NAMED_IAM \\\n",
    "    --region us-east-1\n",
    "\n",
    "# Monitor stack creation\n",
    "aws cloudformation describe-stacks \\\\\n",
    "    --stack-name hcls-bedrock-agents-byot-aho-stack \\\\\n",
    "    --query 'Stacks[0].StackStatus'\n",
    "\n",
    "# Get stack outputs once complete\n",
    "aws cloudformation describe-stacks \\\\\n",
    "    --stack-name hcls-bedrock-agents-byot-aho-stack \\\\\n",
    "    --query 'Stacks[0].Outputs'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in environment variables to notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve import path\n",
    "%store -r IMPORTS_PATH\n",
    "\n",
    "# Retrieve account info\n",
    "%store -r account_id\n",
    "%store -r region\n",
    "\n",
    "# Retrieve model lists\n",
    "%store -r agent_foundation_model\n",
    "\n",
    "%run $IMPORTS_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure AWS clients and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Explicitly specify the region\n",
    "REGION = 'us-east-1'  # Replace with your stack's region\n",
    "# Configure AWS clients\n",
    "session = boto3.Session()\n",
    "account_id = boto3.client('sts').get_caller_identity()['Account']\n",
    "\n",
    "bedrock = boto3.client('bedrock', REGION)\n",
    "cfn = boto3.client('cloudformation', REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get CloudFormation Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "\n",
    "STACK_NAME = 'hcls-bedrock-agents-byot-aho-stack'\n",
    "\n",
    "# Initialize the CloudFormation client with the specific region\n",
    "cloudformation = boto3.client('cloudformation', region_name=REGION)\n",
    "\n",
    "def get_cloudformation_outputs(stack_name):\n",
    "    try:\n",
    "        response = cloudformation.describe_stacks(StackName=stack_name)\n",
    "        outputs = {}\n",
    "        for output in response['Stacks'][0]['Outputs']:\n",
    "            outputs[output['OutputKey']] = output['OutputValue']\n",
    "        return outputs\n",
    "    except ClientError as e:\n",
    "        print(f\"Error getting CloudFormation outputs: {e}\")\n",
    "        raise\n",
    "\n",
    "# Get the outputs from CloudFormation\n",
    "cf_outputs = get_cloudformation_outputs(STACK_NAME)\n",
    "print(\"CloudFormation Outputs:\")\n",
    "print(json.dumps(cf_outputs, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_function_arn = cf_outputs[\"TriggerFunctionArn\"]\n",
    "lambda_function_name = \"hcls-bedrock-agents-byot-a-WorkflowTriggerFunction\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Bedrock Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define agent configuration\n",
    "agent_name = 'ProteinDesignAgent'\n",
    "agent_description = \"Agent for protein design using HealthOmics workflow\"\n",
    "agent_instruction = \"\"\"You are an expert in protein design and optimization using AWS HealthOmics workflows. \n",
    "Your primary task is to help users run protein design optimization workflows and provide relevant insights.\n",
    "\n",
    "When providing your response:\n",
    "a. Start with a brief summary of your understanding of the user's query.\n",
    "b. Explain the steps you're taking to address the query. Ask for clarifications from the user if required.\n",
    "c. Present the results of the workflow execution.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_foundation_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Agent Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate agent with the desired configuration\n",
    "agents = AgentsForAmazonBedrock()\n",
    "\n",
    "protein_design_agent = agents.create_agent(\n",
    "    agent_name,\n",
    "    agent_description,\n",
    "    agent_instruction,\n",
    "    agent_foundation_model,\n",
    "    code_interpretation=False,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Extract useful agent information\n",
    "protein_design_agent_id = protein_design_agent[0]\n",
    "protein_design_agent_arn = f\"arn:aws:bedrock:{REGION}:{account_id}:agent/{protein_design_agent_id}\"\n",
    "\n",
    "print(f\"Agent created with ID: {protein_design_agent_id}\")\n",
    "print(f\"Agent ARN: {protein_design_agent_arn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Action Group Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_defs = [\n",
    "    {\n",
    "        \"name\": \"trigger_aho_workflow\",\n",
    "        \"description\": \"Trigger the AWS HealthOmics workflow for protein design optimization\",\n",
    "        \"parameters\": {\n",
    "            \"workflowId\": {\n",
    "                \"description\": \"The ID of the HealthOmics workflow to run\",\n",
    "                \"required\": True,\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"runName\": {\n",
    "                \"description\": \"Name for the workflow run\",\n",
    "                \"required\": True,\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"container_image\": {\n",
    "                \"description\": \"ECR image URI for the protein design container\",\n",
    "                \"required\": True,\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"seed_sequence\": {\n",
    "                \"description\": \"The input protein sequence to optimize\",\n",
    "                \"required\": True,\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"outputUri\": {\n",
    "                \"description\": \"S3 URI where the workflow outputs will be stored\",\n",
    "                \"required\": True,\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"roleArn\": {\n",
    "                \"description\": \"ARN of the IAM role for workflow execution\",\n",
    "                \"required\": True,\n",
    "                \"type\": \"string\"\n",
    "            }\n",
    "        },\n",
    "        \"requireConfirmation\": \"DISABLED\"\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Action Group with Lambda Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add action group with Lambda function\n",
    "agents.add_action_group_with_lambda(\n",
    "    agent_name=agent_name,\n",
    "    lambda_function_name=lambda_function_name,\n",
    "    source_code_file=lambda_function_arn,\n",
    "    agent_action_group_name=\"ProteinDesignActions\",\n",
    "    agent_action_group_description=\"Actions for protein design using AWS HealthOmics workflows\",\n",
    "    agent_functions=function_defs,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Lambda Resource-Based Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_client = boto3.client('lambda', REGION)\n",
    "\n",
    "try:\n",
    "    # Add the new statement to the existing policy\n",
    "    response = lambda_client.add_permission(\n",
    "        FunctionName=lambda_function_arn,\n",
    "        StatementId=\"AllowBedrockAgentAccess\",\n",
    "        Action=\"lambda:InvokeFunction\",\n",
    "        Principal=\"bedrock.amazonaws.com\",\n",
    "        SourceArn=protein_design_agent_arn\n",
    "    )\n",
    "    \n",
    "    print(\"Resource policy added successfully.\")\n",
    "    print(\"Response:\", response)\n",
    "except lambda_client.exceptions.ResourceConflictException:\n",
    "    print(\"Permission already exists\")\n",
    "except Exception as e:\n",
    "    print(f\"Error adding permission: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Agent Alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agent alias\n",
    "protein_design_agent_alias_id, protein_design_agent_alias_arn = agents.create_agent_alias(\n",
    "    protein_design_agent[0], 'v1'\n",
    ")\n",
    "\n",
    "# Store the alias ARN for future use\n",
    "%store protein_design_agent_alias_arn\n",
    "\n",
    "print(f\"Agent alias created with ID: {protein_design_agent_alias_id}\")\n",
    "print(f\"Agent alias ARN: {protein_design_agent_alias_arn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_agent_runtime_client = boto3.client(\"bedrock-agent-runtime\", REGION)\n",
    "session_id = str(uuid.uuid1())\n",
    "\n",
    "test_query = \"Can you help me optimize a protein sequence?\"\n",
    "\n",
    "response = bedrock_agent_runtime_client.invoke_agent(\n",
    "    inputText=test_query,\n",
    "    agentId=protein_design_agent_id,\n",
    "    agentAliasId=protein_design_agent_alias_id,\n",
    "    sessionId=session_id,\n",
    "    enableTrace=True\n",
    ")\n",
    "\n",
    "print(\"Request sent to Agent:\\n{}\".format(response))\n",
    "print(\"====================\")\n",
    "print(\"Agent processing query now\")\n",
    "print(\"====================\")\n",
    "\n",
    "# Initialize an empty string to store the answer\n",
    "answer = \"\"\n",
    "\n",
    "# Iterate through the event stream\n",
    "for event in response['completion']:\n",
    "    # Check if the event is a 'chunk' event\n",
    "    if 'chunk' in event:\n",
    "        chunk_obj = event['chunk']\n",
    "        if 'bytes' in chunk_obj:\n",
    "            # Decode the bytes and append to the answer\n",
    "            chunk_data = chunk_obj['bytes'].decode('utf-8')\n",
    "            answer += chunk_data\n",
    "\n",
    "print(\"Agent Answer: {}\".format(answer))\n",
    "print(\"====================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"workflowId\": \"8811413\",\n",
    "  \"runName\": \"test-protein-design-run\",\n",
    "  \"parameters\": {\n",
    "    \"container_image\": \"851725420776.dkr.ecr.us-east-1.amazonaws.com/protein-design-evoprotgrad:latest\",\n",
    "    \"seed_sequence\": \"MKFLILLFNILCLFPVLAADNHGVGPQGASGVDPITFDINSNQTGPAFLTAVEMAGVKYLQVQHGSNVNIHRLVEGNVVIWENASTPLYTGAIVTNNDGPYMAYVEVLGDPNLQFFIKSGDAWVTLSEHEYLAKLQEIRQAVHIESVFSLNMAFQLENNKYEVETHAKNGANMVTFIPRNGHICKMVYHKNVRIYKATGPTETQNLQVLFKTAGVIPENKDWWHIFKASRVMKGLEDVDILQCLYVNLYTMITPMLNPFIYSLRNRDTLLASDNAGFGAERDGSCPEAPMCYTIDVNMNMAVRGLFVRPQIPLTGYHGQEFFFKDQRGIHHHHHH\"\n",
    "  },\n",
    "  \"outputUri\": \"s3://hcls-bedrock-agents-byot-aho/output/\",\n",
    "  \"roleArn\": \"arn:aws:iam::851725420776:role/hcls-bedrock-agents-byot-aho--WorkflowExecutionRole-VrUcU3Yr1Wzq\"\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
